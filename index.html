<!doctype html>
<html lang="en">
<head>
<title>DS 4440: Practical Neural Networks</title>
<meta property="og:title" content"Analysis: Densely Connected Convolutional Networks" />
<meta name="twitter:title" content="Your Project Name" />
<meta name="description" content="Your project about your cool topic described right here." />
<meta property="og:description" content="Your project about your cool topic described right here." />
<meta name="twitter:description" content="Your project about your cool topic described right here." />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" /> 
<meta name="viewport" content="width=device-width,initial-scale=1" />
<!-- bootstrap for mobile-friendly layout -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link href="style.css" rel="stylesheet">

</head>
<body class="nd-docs">
<div class="nd-pageheader">
 <div class="container">
 <h1 class="lead">
 <nobr class="widenobr">Densely Connected Convolutional Network</nobr>
 <nobr class="widenobr">For DS 4440</nobr>
 </h1>
 </div>
</div><!-- end nd-pageheader -->

<div class="container">
<div class="row">
<div class="col justify-content-center text-center">
<h2>An Analysis of Densely Connected Convolutional Network</h2>
</div>
</div>
<div class="row">
<div class="col">

<h2>Introduction</h2>
<p>Densely Connected Convolutional Network, or DenseNet, is a model architecture that leverages the fact that
  convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain 
  shorter connections between layers close to the input and those close to the output. Instead of the traditional 
  convolutional networks with L layers that have L connections - one between each layer and its subsequent layer - DenseNet
  has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, 
  and its own feature-maps are used as inputs into all subsequent layers. As a result, DenseNet provides several
  compelling advantages; they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage
  feature reuse, and substantially reduce the number of parameters.</p>
<p>On four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet),
  DenseNets seems to obtain significant accuracy compared to a previous Convolutional Network Architecture in class - ResNet.
  For our analysis, we want to explore and compare DenseNet to ResNet in terms of Efficienecy/ Computational resource 
  use, Performance, and Applications, as well as exploring the limitations of DenseNet.
</p>
<h2>Paper Review</h2>


<p>We have talked about the vanishing gradient problem where the input or gradient can vanish and "wash out" by
  the end of the network after passing through many layers. There are many ways of tackling this problem: bypassing signals from one layer to the next via identity connections or
  randomly dropping layers during training to allow better information and gradient flow. Both of those approaches share a distinct characteristic:
  they create short paths from early layers to later layers.
</p>
<p>DenseNet was introduced as a way to distill this insight into an architecture: Instead of the traditional 
  convolutional networks with L layers having L connections - one between each layer and its subsequent layer - DenseNet
  has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, 
  and its own feature-maps are used as inputs into all subsequent layers. Crucially, in contrast to ResNets, 
  DenseNet never combines features through summation before they are passed into a layer; instead, they combine 
  features by concatenating them. These features help DenseNet achieve 3 effects: it requires fewer parameters, it avoids the vanishing gradient
problem, and it provides a regularizing effect on small datasets.</p>
<img src="resource\DenseNet_vs_ResNet.png" alt="Architecture">
<p>Having talked about DenseNet's advantages, we also want to explore its drawbacks: Memory access cost grows quadratically for each additional layer
  for DenseNet as compared to ResNet due to Densenet's concatenating nature: each downstream layer has to access all feature maps in the same DenseBlcok. Thus,
  we want to compare the two models against each other to see if one is better than the other.</p>

<h3>Section 3: Method & Implementation</h3>
<p>We will be training both untrained ResNet and DenseNet models with 100 depth and 200 depth on the <a href="https://huggingface.co/datasets/zh-plus/tiny-imagenet" 
  target="_blank" rel="noopener noreferrer">TinyImageNet dataset</a> which is a smaller dataset of the ImageNet Dataset and the <a href="https://www.cs.toronto.edu/~kriz/cifar.html" 
  target="_blank" rel="noopener noreferrer">CIFAR-10 dataset</a> . On these datasest, 
  we will run the model for 50 epochs and evaluate both models in terms of:</p>
<ul>
  <li>Accuracy</li>
  <li>Training time</li>
</ul>
<p>to see if the two models have the same performance over time and identify when one should use DenseNet and when one should use ResNet</p>

<h4>Section IV: Experimental Findings</h4>
<p>Our experiments aimed to evaluate the performance of our implementation of Resnet and DenseNet on new datasets and with reduced training data. While the paper reports impressive
  results in terms of accuracy and parameters for DenseNet vs traditional ResNet, we want to discover if that is the case when taking into account training time.
  When performing classification on the CIFAR-10 Datasets with both models having 101 layers, DenseNet represents an <b>initial faster prediction ability through its information
  preservation ability</b> as the model yielded a significantly higher initial accuracy rate as compared to ResNet with 58.24% for the first epoch
  accuracy for DenseNet and 34.13% accuracy for ResNet with the disadvantage of requiring more GPU resources (requiring 1.5GB for DenseNet vs 700MB for ResNet).
  This is a testament to its robustness and capability in handling complex image recognition tasks for small datasets such as TinyImagenet and CIFAR-10  as compared to ResNet. 
  This interesting result also follows as the two models train for more epochs on these two small datasets, with DenseNet achieving a visibly higher accuracy with a top accuracy of <b>76.83% over 50 epochs</b> as compared to
ResNet with a top accuracy of <b>70.88%</b>. However, one note-worthy result is the number of <b>time it takes to train one epoch for DenseNet vs ResNet is significantly different as it takes approximately 60 seconds to train 
an epoch for ResNet vs 97 seconds for an epoch of DenseNet. When applying more epochs to ResNet, we can see that ResNet exhibits a top accuracy of 75.5%, 1.5% lower than DenseNet.</b></p>
<img src="resource\download.png" alt="AccuracyCIFAR-10", class = "AccuracyCIFAR-10">
<img src="resource\AccuracyEpochCIFAR-10.png" alt="AccuracyCIFAR-10", class = "AccuracyCIFAR-10">

<p>The same pattern is observed in the TinyImageNet dataset where we run the two models for 20 epochs. ResNet exhibits a faster training time as compared to DenseNet with
  the tradeoff of lower accuracy per epoch and a lower top accuracy of 33.24% as compared to DenseNet's 43.14% top accuracy. In this case, the difference in accuracy is more prominent
  as the TinyImageNet dataset has more classes, and with low epochs, it is harder for ResNet to generalize the pattern as compared to DenseNet with the same layers.
</p>
<img src="resource\AccuracyTimeTinyImageNet.png" alt="AccuracyCIFAR-10", class = "AccuracyCIFAR-10">
<img src="resource\AccuracyEpochTinyImageNet.png" alt="AccuracyCIFAR-10", class = "AccuracyCIFAR-10">
<p>However, when increasing the layers for DenseNet from 100 to 200, the training time doubles to 175 seconds per epoch for the CIFAR-10 Dataset while the accuracy is around the same, or sometimes even lower for DenseNet with
  more layers. This is due to the dense connections and concatenations of feature maps from all preceding layers leading to DenseNets becoming quite memory intensive,
    especially as the network depth increases. This issue is less prominent with ResNet as it's preserving information through identity mapping, not by concatenating, so the memory cost
  is linear. </p>

<h4>Section V: Conclusions</h4>
<p>With ResNet using skip connections to implement identity mappings, allowing gradients to flow through the network without attenuation whereas DenseNet uses dense connections, concatenating feature maps from all preceding layers,
training time to get to a certain accuracy for both models is significantly different with ResNet training time and computational requirements being significantly lower than DenseNet to get to the same accuracy.
Having said that, <b>DenseNet's ability to regularize with small datasets and feature reuse throughout the network allows for better accuracy and is suitable for shallow networks with small datasets</b>. <b>ResNet, on the other hand,
is more suitable for deeper networks with its low computational requirements, shorter training time, and simplicity, which helps with hyperparameter tuning.</b>
<h3>References</h3>

<p><a name="DenseNet">[1]</a> <a href="https://arxiv.org/pdf/1608.06993.pdf"
  >L&eacute;Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Q. Weinberger.
  <em>Densely Connected Convolutional Networks.</em></a>
  (2018).
</p>

<h2>Team Members</h2>
                                                   
<p>Khoa Anh Vo</p>
<p>Jake Fuiman</p>

  
</div><!--col-->
</div><!--row -->
</div> <!-- container -->

<footer class="nd-pagefooter">
  <div class="row">
    <div class="col-6 col-md text-center">
      <a href="https://cs7150.baulab.info/">About CS 7150</a>
    </div>
  </div>
</footer>

</body>
<script>
$(document).on('click', '.clickselect', function(ev) {
  var range = document.createRange();
  range.selectNodeContents(this);
  var sel = window.getSelection();
  sel.removeAllRanges();
  sel.addRange(range);
});
// Google analytics below.
window.dataLayer = window.dataLayer || [];
</script>
</html>
